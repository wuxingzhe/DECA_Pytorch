common: &common
  eval_train: False
dataset:
  image_size: 224
  uv_size: 256

model:
  topology_path: './data/head_template.obj'
  dense_template_path: './data/texture_data_256.npy'
  fixed_displacement_path: './data/fixed_displacement_256.npy'
  flame_model_path: './data/generic_model.pkl'
  flame_lmk_embedding_path: './data/landmark_embedding.npy'
  face_mask_path: './data/uv_face_mask.png'
  face_eye_mask_path: './data/uv_face_eye_mask.png'
  mean_tex_path: './data/mean_texture.jpg'
  tex_path: './data/FLAME_albedo_from_BFM.npz'
  tex_type: 'BFM'
  useTex: True
  use_tex: True
  jaw_type: 'aa'

  param_list: ['shape', 'tex', 'exp', 'pose', 'cam', 'light']
  n_shape: 100
  n_tex: 50
  n_exp: 50
  n_cam: 3
  n_pose: 6
  n_light: 27

  n_detail: 128
  max_z: 0.01

pretrained_model:
  recog_network: ''

train_params:
  ldmk_loss_factors: [0.0001, 1.0]
  eye_closure_loss_factors: [1.0, 1.0]
  regular_loss_factors: [0.0001, 0.0001]
  shape_consistency_loss_factor: 1.0
  photometric_loss_factor: 2.0

  norm_type_ldmk: 'mse'
  norm_type_eye_closure: 'mse'
  norm_type_reg: 'mse'
  norm_type_photometric: 'mse'

  batch_sizes: [64, 32]
  workers: 4
  crop_size: 224
  scale: 1.0
  iscrop: False

  kpts_gt_dir: 'ldmk_gt'
  seg_masks_dir: 'face_seg_res'
  train_list: ''
  train_subject_list: ''

  ldmk_weights_file: ''
  eye_closure_ldmk_idx_file: ''

  person_size:
  size_per_person:
  person_num_in_batch: 8
  size_per_person_in_batch: 4

  optimizer:
    type: Adam
    kwargs:
      lr: 0.0001
      weight_decay: 0.0005
  scheduler:
    epochs: 4
    milestones: [5, 10]
    gamma: 0.5
  epoch_phase: 2

test_params:
  batch_size: 3
  works: 1
  crop_size: 224
  scale: 1.0
  iscrop: False
  qualitative_test_list:

recog_params:
  feature_dim:
  drop_ratio: